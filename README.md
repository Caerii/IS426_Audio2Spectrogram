# IS426_Audio2Spectrogram
Processes audio into usable spectrograms for classification

# There are several processing steps
The program should ask for which *classes of data* you are going to be processing. 

This will create empty folders, and the program
will ask you to select the files on your computer which correspond to that class.

These files will be cloned into a folder in the root directory of the program in "./data"

So you've got these audio files. There is a function (waveformIngestion()) that takes in the:
-frequency of the audio data (whether it be 44100 or 48000 or something),
this will determine the array size for the audio.
-url of each audio file
-the "chunk" size that you want to break the audio down into

This will be applied to all of the audio clips.

So next you're going to have a folder structure be autogenerated from this function which takes an audio clip,
and the audio will be split into chunks proportional to the total size of the clip,
each audio clip will spawn one folder that has all of the clips of the chunks inside of it.

This means in each class folder, you'll have a large amount of folders corresponding to the amount
of examples that exist for that particular class.

This repository will process AudioMNIST, a dataset composed of spoken data of the digits 0-9.
